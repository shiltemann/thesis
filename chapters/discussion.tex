\begin{savequote}[75mm]
``Humans are allergic to change. They love to say, `We've always done it this way.'' I try to fight that. That's why I have a clock on my wall that runs counter-clockwise.''
\qauthor{Grace Hopper}
\end{savequote}

\chapter{Discussion}\label{discussion}
\setcounter{figure}{-1}
\setcounter{table}{-1}
\setcounter{section}{-1}
\setcounter{NAT@ctr}{-1}

Since the completion of the human reference genome in 2003, the field of molecular biology has been transformed almost beyond recognition, and along with it, the field of bioinformatics has evolved from a niche discipline to an integral part of every biomolecular research question. Where just a couple decades ago most genomic data analyses could largely be performed by hand, nowadays they often require a supercomputer. Programming knowledge is required to run such analyses, but biologists are not typically trained in these skills, and have thus become reliant on bioinformaticians to carry out this work for them. Similarly, bioinformaticians often lack the increasingly complex biological knowledge required to fully interpret the results. Biologist and bioinformatician must therefore work together closely, and each must be trained in the other discipline sufficiently enough to be aware of any factors that might influence analysis or interpretation. Furthermore, data is being generated at an exponential rate (and bioinformaticians are not), and one way to address this gap is to empower researchers to run their own day-to-day analyses after analysis pipelines are fully developed and validated.


\section{Galaxy for open and accessible research}
The Galaxy project~\cite{TODO} is a framework that enables such empowerment of researchers to run complex data analysis without programming expertise. The Galaxy project is free and open-source and community-driven, solliciting feedback and code contributions from its user community to improve and evolve along with the ever-changing landscape that is bioinformatics. \hyperref[chapter:galaxy]{\textbf{Chapter~\ref{chapter:general}}} outlines the ongoing development in the Galaxy framework. Not only are new tools continually integrated by the community, new components are incorporated into the Galaxy code base and existing features improved to evolve and scale with user requirements. On the user-facing side, improvements were made to assist with the handling of large datasets (collections, rule-based uploader) to match the exponential rate of data generation. Accessibility was improved by the integration of a new help forum and the development of a central training materials repository (\textbf{Chapter~\ref{chapter:training}}).


\section{Training}
Training is an essential component in the dissemination of accessible bioinformatics tools and workflows. Training is needed both for researchers looking to analyze their data, as well as for the bioinformaticians developing the tools and workflows. Galaxy is especially well-suited for bioinformatics training because it provides a layer of abstraction, allowing trainees to focus on the bioinformatics \emph{concepts} rather than the nitty-gritty details about the UNIX commandline interface. Take for example a workshop on sequence mapping; when using Galaxy for teaching, the focus can lie purely on the different parameters and their effects on downstream analysis, whereas when teaching the same steps on the commandline, participants would have to learn new details about the UNIX commandline in addition to read mapping. Such an approad increases the cognitive load of students, which may hamper learning~\cite{paas2003cognitive}.

The Galaxy Training Network (GTN) is a loosely define group of instructors around the world who use Galaxy for training purposes, but there was little coordination between the different instructors in terms of materials used, and thus a lot of duplication of effort. Therefore, we set out to create a central repository of Galaxy training materials and a set of best-practice guidelines which could be used by anybody in the community. Any central solution would have to be a collaborative effort if it was to be sustainable and maintainable. In Chapter~\ref{chapter:training} we describe the collaborative web framework for delivery of bioinformatics training using the Galaxy platform that we created in response to this need.

We focused on creating a fully open and transparent framework that is accessible and easy to use for both learners and trainers. All development happens on GitHub, where anybody may suggest additions and changes, and any such proposed changes are thoroughly tested using Travis continuous integration system~\cite{travis-ci} to ensure functionality and adherence to guidelines. The proposed changes or additions to tutorials or the framework are then reviewed by one or more of the volunteers from the community, and changes may be requested. Once approved, the code is merged into the main code base, and the new website is automatically built and deployed by Travis and GitHub. The materials themselves are based around \emph{research stories}; usually the recreation of results described in a published paper. This gives users the confidence that the tools and pipelines they are learning are practically useful and publication-level quality, as well providing them with the opportunity to explore the science and informatics in the paper in full detail. Furthermore, since publication of our work, a number of publications of scientific papers have included Galaxy training materials for readers and as a form of documentation~\cite{TODO}.

One of the main challenges in designing this framework, was to allow easy contributions from instructors, without the need for any web development knowledge. To this end, we used Jekyll templating~\cite{jekyll}, which allows tutorials to be written in the simple and accessible markup language Markdown~\cite{markdown}, which is then automatically converted to a web page. Analogous to how Galaxy allows scientists to run analyses while being abstracted away from the implementation layer of the tools, so does jekyll allow instructors to create web pages for their tutorials without being concerned with the web application layer.

A further challenge was to enable the materials to be usable both by instructors during workshops, as by individuals learning on their own. This is accomplished by including all materials instructors might provide during a workshop in the GTN training materials framework. This includes slides as well as hand-on materials, further reading suggestions, and an automatically created and updated list of Galaxy servers which meet the requirements to run a given tutorial.

\begin{comment}
<closer integration with galaxy servers>

<feedback, planemo, cofests, dashboard, instructor topic, levels, translations, tess search, curricula, toc>

2019: 4 new topics (metabolomics, computational chemistry, data manipulation, ui and features), 66 new tutorials
\end{comment}

Since the initial publication of Chapter~\ref{chapter:training}, we have continued active development of the GTN framework and training materials. As Galaxy evolves, so must the associated tutorials; where Galaxy is expanding beyond bioinformatics and is now also being used in fields such as natural language processing and computational chemistry, so have we noticed a steady expansion of topics and tutorials contributed by the community. In the year following publication, we saw 6 new topics added, 66 new tutorials, and the number of contributors grew from 64 to 137. Where the focus of development initially lay with improving the experience for end-users of the tutorials, in the year since publication, our focus has shifted to support for tutorial contributors and instructors intending to use our materials.

In order to support this growing and diverse community of learners and trainers, constant maintenance and development of the materials is required. One important component that enables this is the collection of feedback, both from learners and instructors. To this end, we integrated feedback forms at the end of each tutorial, and hold regular community meetings with training developers and trainers. By solliciting this feedback, we can continually apply incremental improvements to the materials and any potential shortcomings of the materials can be addressed as they emerge. This community-driven approach is the only way to keep the ever growing number of tutorials up-to-date. Additionally, to further distribute the maintenance burden of the framework, maintainers are assigned to each topic, chosen from volunteers within the community, who are responsible for the tutorials within the topic and who evaluate all pull requests made to the materials.

The main challenge in the coming years will be the community management; creating and sustaining a close-knit community of Galaxy users and instructors so that the project can survive even when its original developers have moved on.


\section{Visualisation and Reporting}

Galaxy is highly flexible, but this comes hand-in-hand with complexity. This trade-off is acceptable for researchers still developing their pipelines, but for clinicians who have fixed and validated workflows, the flexibility is not longer required, and in many cases even undesirable. At this point the relative complexity of the Galaxy interface to novice users may become a hurdle.

One of the main deficits of Galaxy in its current form, is the lack of an appealing system of results reporting. Datasets produced from workflows must be individually viewed by the user. While Galaxy sports a plugin system for visualisation of individual datasets, a generic reporting tool for displaying a set of output datasets together does not exist. To this end, we developed iReport (Chapter~\ref{chapter:general}), a fully customizable Galaxy tool that generates a webpage that can display any number of workflow outputs. In this manner, end-users need only to open a single workflow output to get a full overview of results. The workflow developer can create an iReport fully tailored to the needs of their users, including the ability to add links to datasets and external resources, create searchable and sortable tables, add images and custom text, and to divide content into different pages. In this manner, clinicians and other end users are able to run workflows and view results with minimal instruction and knowledge of the pipelines and Galaxy interface.

Going even further, by using the Galaxy API, simplified web frontends for Galaxy may be created, such that only features needed by the users are exposed. In the case of clinical applications, this provides the additional benefit of protecting user from inadvertently altering any workflow parameters. An example of such a simplified front-end is Galaksio~\cite{galaksio} or IRIDA~\cite{TODO}. Users log in to a custom webpage, are given a list of workflow to choose from, and are asked to provide input datasets. While Galaxy is used to run the analysis, the users never leave their web environment, and everything is handled by the front-end. In order to fully


\section{Use Cases}

The concepts described in the previous sections were applied to two separate use cases. Chapters~\ref{chapter:fusiongenes} and~\ref{chapter:variants} describe the creation of analysis tools and pipelines for (prostate) cancer analysis, and in Chapter~\ref{chapter:microbiota}, Galaxy-based analysis pipelines were built and tested for microbiota profiling. While from a biological perspective these application fields are quite distinct, from a bioinformatics perspective they share many similarities. Both involve genome sequencing data, which have to be quality checked and mapped to a reference sequence or database. After these common steps the pipelines start to diverge more significantly; where the cancer pipelines focus on variant detection, microbiota profiling is concerned with the identification of the microbial entities present. Both have the ultimate end-goal of improving understanding of the biological mechanisms involved, and facilitating the diagnosis and treatment of patients. To that end, the incorporation of steps to visualize the large result files and reporting the various pipeline outcomes in a unified report are again shared steps between both use cases. Where the prostate cancer pipelines were developed mainly for research purposes, the microbiota pipeline was developed for direct clinical use, posing additional challenges in terms of accuracy and robustness.


\subsection{Cancer Analysis: Fusion Gene Detection}
\subsubsection{The Bio}

Prostate cancer is one of the most commonly diagnosed cancer types in men \cite{jemal2010global}, and while many patients present with an indolent form of the disease, others develop a highly aggressive tumour type, and overall, prostate cancer is among the top 10 leading causes of cancer-related deaths in men. The presence of the TMPRSS2-ERG gene fusion is observed in approximately 50\% of prostate cance patients~\cite{tomlins2005recurrent}, and many other less frequent fusions have also been detected. Fusion genes may arise when structural variants (SVs) occur within two different genes, causing the creation of hybrid genes with the potential to produce hybrid proteins that may disrupt vital cell functions.

Chromothripsis is a phenomenon observed primarily in cancer cells, that involves the shattering and subsequent imprecise repair of one or more chromosomes in a single catastrophic event. Chromothripsis is characterized by the observation of 1) large numbers of chromosomal rearrangements on a localized parts of the genome, 2) alternations between a small number of different copy number states, and 3) alternation between regions displaying a loss of heterozygosity (LOH) and those with preserved heterozygosity~\cite{maher2012chromothripsis}.

Chapter \ref{chapter:fusiongenes} describes the identification of chromothripsis in the 5q arm of the VCaP cell line. A very large number of SVs were described, and copy number varied primarily between two copy number states states, with only sporadic occurrences of a third state. This alternation between a small number of copy number states suggest the rearrangements were precipitated by a single catastrophic event.

The 573 rearrangements involving this part of chromosome 5 were then investigated for their potential to lead to the formation of fusion genes. Out of this large number of rearrangements, only 18 were found to occur between two different genes at consistent orientation. These fusion gene candidates were confirmed via sequencing using custom PCR. This allowed us to confirm 16 out of 18 fusion candidates on the DNA level, but only 5 of these were also measured on the mRNA level, suggesting instability of the fusion transcripts or down-regulation of gene expression.

Overall, this research has shown that any studies involving this commonly used prostate cancer cell line should take the presence of chromothripsis on chromosome 5q into account, as well as its utility as a model for research on chromothripsis.

\subsubsection{The Informatics}
Whole-genome sequence experiments typically generate very large output files. Furthermore, in the case of structural variant analysis, the output file formats lack consistency across tools and sequencing platforms, and interpretation is greatly helped by visualisation and annotation with external data resources. To this end, the iFUSE application was developed, creating a visual representation of fusion gene candidates and computing various metrics such as predictions of fusion protein product.

While iFUSE provides valuable aid in interpretation on a per-event basis through its visualisation and annotation, it is less suitable for getting a genome-wide overview of structural rearrangements. Large-scale rearrangements such as chromothripsis for instance are easy to miss when examining the raw textual output files or the iFUSE visualisations. In order to evaluate the presence of chromothripsis, a more high-level view of the genome is needed, and to that end, whole-genome visualisations were created using Circos~\cite{circos} for rearrangements, and GNUplot~\cite{url-gnuplot} for the copy number and heterozygosity plots. This approach enabled the instant identification of chromothripsis present in the VCaP sample, which could then be followed up by closer examination of individual rearrangements involving the chromosome 5q using iFUSE.

Both the iFUSE application, the Circos Galaxy wrappers, and the other tools and visualisations created in this chapter are open-source and publicly available on an example server, and are accompanied by extensive documentation to enable re-use by institutes that may have legal restrictions about the use of clinical samples on public servers. By using Galaxy


\subsection{Cancer Analysis: Somatic Mutation Determination}
\subsubsection{The Bio}
One of the main challenges in analysis of oncological samples is the identification of those mutations that potentially function as oncogenic drivers, and the large number of passenger mutations or polymorphisms present in the germline of the patient that are typically deemed to be functionally benign~\cite{lawrence2013mutational}. To this end, a sample of normal tissue from the same individual is often sequenced in conjunction with the tumour sample. This allows the subtraction of germline variants from the set of mutations detected in the cancer sample, in order to narrow down the set of potential driver mutations. However, in practice such an associated normal sample may not always be available, for a variety of reasons. In such cases, an alternative approach is required.

Given the observation that the majority of any individuals germline variants are polymorphic and observed frequently in the human population~\cite{TODO}, in combination with the exponential increase in publicly available genomic datasets, we explored the suitability of constructing a so-called \emph{virtual normal}, consisting of a reference set of variants found in the population. Chapter \ref{chapter:variants} describes this investigation.

Our approach used a set of over 900 publicly available whole genomes from healthy, ethnically diverse individuals. We combined this with the customary approach of annotating variants for presences in several online databases of polymorphism in the human population. We tested the performance of our method using 4 different tumour samples with matched normals, 2 of which had been sequenced on two different platforms (Complete Genomics and Illumina).

Our results show that while highly unique personal variants cannot be corrected for, a large number of polymorphisms may be removed without the need of an associated normal sample from the same individual, and as more and more WGS samples are made publicly available, ever rarer variants may be corrected for in this manner. Furthermore, we demonstrated that the use of a virtual normal consisting of whole-genome variant files provided a significant improvement over using only the online variant databases. This observation can be explained by noting that variants may be described in various different yet equivalent ways. These variant descriptions are not standardized, and it may not even be possible to do so. However, having knowledge of the area surrounding variants enables more advanced comparison algorithms to resolve equivalency of variants where routine position-based exact comparison method fall short. Therefore, comparing variants between samples, especially those sequenced on different platforms, is problematic without knowledge of surrounding variants in the same samples. This information is typically lost in online variant databases, which explains the increased performance of the virtual normal approach. Moreover, when using only an associated normal and online variant databases resulted in a roughly equal number of false-positive somatic variants (e.g. variants determined to be somatic but which were polymorphism based on virtual normal analysis), as did the approach without a matched normal. This can be explained by a combination of sequencing errors or incorrect variant calling in the associated normal samples, and the general difficulty presented in variant comparison analyses.

Where possible, using a combination of all three approaches -matched normal, virtual normal, and online polymorphism databases- yields optimal results, but in cases where no matched normal is available, relying on only the latter two correction sources provides an accurate alternative. Depending on the use case, the decrease in power to detect highly personal germline variants may be offset by the decrease in cost from the absence of necessity of sequencing a mathed normal sample with every tumour sample.

\subsubsection{The Informatics}
The samples in this study were sequenced by Complete Genomics~\cite{TODO}, a sequencing service which delivers both raw sequencing data and post-processed results. They provide a suite of command line tools for handling and further analysis of their often custom file formats. As a first step towards building the virtual normal analysis pipelines, these existing tools were wrapped into Galaxy. On top of these third party tools, several custom analysis components had to be created, as well as several file format conversion steps to function as a \emph{glue} between steps.


\subsection{Microbiota Profiling for Clinical Diagnostics}
\subsubsection{The Bio}
The MYcrobiota project described in Chapter~\ref{chapter:microbiota} was aimed at developing a 16S microbiota profiling pipeline suitable for use in a clinical setting, in order to augment or eventually potentially replace the culture-based methods currently employed in microbial diagnostic laboratories. While 16S sequencing is a relatively well-established technique, there are several obstacles yet to overcome to enable its use in routine diagnostics. These obstacles include 1) the high prevalence of chimera formation during PCR amplification~\cite{huttenhower2012structure}, 2) the inability to standardize the relative abundance results obtained from 16S profiling across different studies, and 3) the lack of a user-friendly bioinformatics pipeline that can be operated by clinicians without extensive bioinformatics knowledge.

The MYcrobiota platform is the result of a close collaboration with Streeklab Haarlem~\cite{TODO}, a microbial diagnostics lab servicing a large number of GPs and hospitals in the region. In order to facilitate the use of 16S rRNA sequencing in a diagnostic setting, several enhancements to standard procedure were required, both in the wet lab and the bioinformatics pipelines to overcome the aforementioned obstacles.

The MYcrobiota platform utilizes the micelle PCR (micPCR) method~\cite{boers2015micelle,boers2017novel}. In this approach, PCR amplifications of each template 16S template sequence occurs in a physically distinct reaction environment called a micelle, thus greatly reducing the generation of hybrid sequences known as chimeras. This approach has the additional benefit of allowing for the absolute quantification of abundance by eliminating PCR competition induced bias. To further improve the accuracy of the results, each sample was sequenced in triplicate and averaged in order to eliminate any remaining quantification bias in the micPCR protocol. A further correction is performed with a negative extraction control sample sequenced with every batch. Finally, and internal calibrator (IC) was used to enable quantification of each resulting OTU in terms of the number of gene copies rather than relative abundances. This IC consisted of a known quantity of a bacterium not present in the natural microbial flora under investigation added to the samples before PCR amplification.

Results were validated through the analysis of 47 clinical samples obtained from patients presenting with a variety of damaged skin conditions, and results were compared to the culture-based methods currently employed for routine clinical microbial diagnostics. The results showed that the vast majority (>95\%) of genera detected by routine culturing were also detected by the MYcrobiota platform. Conversely, the majority of bacterial taxa detected by MYcrobiota were not identified by culture, and many of these additional genera detected were obligate anaerobes consistent with previous studies \cite{TODO}, and included potential pathogens such as \emph{Kingella} not detected in routine culture.

The universality of the MYcrobiota pipeline has been subsequently demonstrated through its application to environmental studies in drinking water distribution systems~\cite{boers2018monitoring} and in a clinical setting involving patients presenting with suspected septic arthritis~\cite{boers2018detection}.

It must be noted however, that certain limitations to the MYcrobiota remain, and further development and extensive clinical validation studies are required before introduction into routine diagnostics. For example, the current methodologies lack the discriminative power to differentiate to the species taxonomic level, which is often essential for clinical diagnostics. However, results could be supplemented with species-specific PCRs. Alternatively, relatively simple alterations to the current MYcrobiota platform could accommodate approaches such as the sequencing of multiple hypervariable regions or full-gene 16S rRNA, as well as other potential genetic markers such as \emph{rpoB}~\cite{adekambi2009rpob}, \emph{gyrB}~\cite{yanamoto1995pcr}, the ITS region~\cite{schoch20012nuclear}, or one of many other potential markers capable of differentiation of prokaryotes at the species taxonomic level \cite{lab2016marker,sabat2017targeted}.

In conclusion, the development of the MYcrobiota platform paves the way for the introduction of culture-free quantitative microbiota profiling methods into clinical diagnostic laboratories. It is capable of providing a highly accurate and comprehensive profile of the microbial composition of clinical samples, even at low biomass, and may provide clinicians with valuable information on potential pathogens not (easily) provided by the standard culture-based methods. Alternatively, the culture-negative status of clinical samples may be confirmed by the absence of 16S rRNA gene copies in the MYcrobiota results.

\subsubsection{The Informatics}

\textbf{Tools}. As a first step to creating the MYcrobiota platform, we incorporated the full suite of 125+ mothur tools~\cite{schloss} into Galaxy, as well as the Krona~\cite{ondov2015krona} tool and Phinch~\cite{bik2014phinch} display application for visualisation of tools. To facilitate the interoperability of these tools and others already available in Galaxy, we also created some file format conversion tools to function as the \emph{glue} between steps and facilitate the interoperability with existing downstream tools through the support of widely used file formats such as the BIOM format~\cite{mcdonald2012biological}.


\textbf{Workflows}. In order to optimize utility of the tools, several standard pipelines were provided in Galaxy, based on available standard operating procedures (SOPs) defined in the research community. However, for use as clinical pipelines, further customizations were required, for instance to support the experimental setups utilizing such methods as replicates, negative extraction controls, as well as additional alterations necessitated by the use of micPCR protocol, such as the use of an IC for quantification. To accommodate these custom requirements, the standard pipelines had to be augmented with additional components and custom parameter settings, arrived at through a lengthy cycle of testing and adjustment, followed by clinical validation. In order to facilitate scaling of these analysis, the pipelines utilize Galaxy collections, enabling analysis sizes from single sample to tens of thousands of samples.

\textbf{Visualisation and Reporting}. The MYcrobiota pipelines generate hundreds of files per run per sample, so a tailor-made web report was configured using the iReport tool described in Chapter \ref{chapter:ireport} to aid clinicians in the interpretation of results. This report included several integrations with external resources such as BLAST and prokaryotic databases.

\textbf{Open science and bioinformatics best practices}. In order to optimize the utility of the tools and pipelines both now and in the future, all components of the MYcrobiota are open-source and publicly available on GitHub, and under testing using the Travis continuous integration platform. The advantages of this approach are illustrated by the fact that since its release, the tools have received numerous updates and bug fixes from members of the Galaxy community, relieving the maintenance burden for us as original authors and keeping the tools relevant as the underlying mothur components evolve.

\textbf{Training}. Galaxy training materials were developed to facilitate the dissemination of the MYcrobiota tools and pipelines. These were integrated into the training infrastructure developed in Chapter~\ref{chapter:training}, and have since been used in numerous workshops by a variety of instructors in the Galaxy Training Network, as well as for self-study by individual learners online. Due to the feedback mechanisms built into the Galaxy training framework, learner feedback is collected, and we have received and implemented many suggestions for improvements, enabling incremental development and refinement of the materials.

\section{Future Perspectives}

Galaxy: reporting, bigger data, other application, IDC, shared reference data,

\subsection{The Bio: Futuromics}
single cells, real-time, bigger data

microbiota: long reads to improve shotgun analysis, or 16S higher accuracy

\subsection{The Informatics}

Galaxy in the clinic: reporting, frontends

Open Science! Open Science! Open Science!

\bibliographystyle{ieeetr}
\bibliography{references}
